{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "64bceb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class VectorValue:\n",
    "    def __init__(self, data, _children = (), _op: str = \"\", label: str = \"\"):\n",
    "        if isinstance(data, (int, float)):\n",
    "            self.data = [float(data)]\n",
    "        else:\n",
    "            self.data = list(data)\n",
    "            \n",
    "        self.grad = [0.0 for _ in self.data]\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"VectorValue(data = {self.data})\"\n",
    "    \n",
    "    # Addition(s)\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, VectorValue) else VectorValue(other)\n",
    "        assert len(self.data) == len(other.data)\n",
    "\n",
    "        out_data = [a + b for a, b in zip(self.data, other.data)]\n",
    "        out = VectorValue(out_data, (self, other), \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.grad)):\n",
    "                self.grad[i] += out.grad[i]\n",
    "                other.grad[i] += out.grad[i]\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        # Handle sum() starting with 0: convert other to VectorValue\n",
    "        other = other if isinstance(other, VectorValue) else VectorValue(other)\n",
    "        return self + other\n",
    "    \n",
    "\n",
    "    # Multiplications\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, VectorValue) else VectorValue(other)\n",
    "        assert len(other.data) == len(self.data)\n",
    "        out_data = [a * b for a, b in zip(self.data, other.data)]\n",
    "        out = VectorValue(out_data, (self, other), \"*\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.grad)):\n",
    "                self.grad[i] += other.data[i] * out.grad[i]\n",
    "                other.grad[i] += self.data[i] * out.grad[i]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    \n",
    "    # Dot product\n",
    "    def dot(self, other):\n",
    "        assert len(self.data) == len(other.data)\n",
    "        out_data = [sum(a * b for a, b in zip(self.data, other.data))]\n",
    "        out = VectorValue(out_data, (self, other), \"dot-product\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.grad)):\n",
    "                self.grad[i] += other.data[i] * out.grad[0]\n",
    "                other.grad[i] += self.data[i] * out.grad[0]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out  \n",
    "    \n",
    "    # Sum\n",
    "    def sum(self):\n",
    "        out_data = [sum(self.data)]\n",
    "        out = VectorValue(out_data, (self, ), \"sum\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += out.grad[0]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    # Activations\n",
    "\n",
    "    def relu(self):\n",
    "        out_data = [max(0.0, x) for x in self.data]\n",
    "        out = VectorValue(out_data, (self, ), \"ReLU\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += (self.data[i] > 0) * out.grad[i]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        out_data = [math.tanh(x) for x in self.data]\n",
    "        out = VectorValue(out_data, (self,), \"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += (1 - out.data[i]**2) * out.grad[i]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "             \n",
    "    \n",
    "    # Negation\n",
    "    def __neg__(self):\n",
    "        return self * -1\n",
    "    \n",
    "    # Subtractions\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        return other + (-self)\n",
    "    \n",
    "    def __pow__(self, power):\n",
    "        assert isinstance(power, (int, float)), \"only supports scalar powers\"\n",
    "\n",
    "        out_data = [x ** power for x in self.data]\n",
    "        out = VectorValue(out_data, (self,), f\"**{power}\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += power * (self.data[i] ** (power - 1)) * out.grad[i]\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if not v in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = [1.0 for _ in self.data]\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "491295bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: VectorValue(data = [1.0, 2.0, 3.0])\n",
      "w: VectorValue(data = [0.5, -1.0, 2.0])\n",
      "b: VectorValue(data = [0.1])\n",
      "y: VectorValue(data = [0.9997979416121845])\n"
     ]
    }
   ],
   "source": [
    "x = VectorValue([1.0, 2.0, 3.0])\n",
    "w = VectorValue([0.5, -1.0, 2.0])\n",
    "b = VectorValue([0.1])\n",
    "\n",
    "# single neuron forward\n",
    "y = (w.dot(x) + b).tanh()\n",
    "y.backward()\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "print(\"y:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f44472f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.00545502529852554, -0.01091005059705108, 0.02182010119410216]\n",
      "w: [0.01091005059705108, 0.02182010119410216, 0.03273015179115324]\n",
      "b: [0.01091005059705108]\n",
      "y: [1.0]\n"
     ]
    }
   ],
   "source": [
    "y = (w.dot(x) + b).tanh()\n",
    "y.backward()\n",
    "\n",
    "print(\"x:\", x.grad)\n",
    "print(\"w:\", w.grad)\n",
    "print(\"b:\", b.grad)\n",
    "print(\"y:\", y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243801b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorValue(data = [1, 4, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = VectorValue([1, 2, 3])\n",
    "b = [1, 2, 3]\n",
    "a *b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cda2fd",
   "metadata": {},
   "source": [
    "### Neural-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95551850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9f660707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = [0.0 for _ in p.grad]\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4f6cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(Module):\n",
    "    def __init__(self, nin, nonlin = True):\n",
    "        self.w = VectorValue(\n",
    "            [random.uniform(-1, 1) for _ in range(nin)], \n",
    "             label='w'\n",
    "        )\n",
    "    \n",
    "        self.b = VectorValue([0.0], label='b')\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x if isinstance(x, VectorValue) else VectorValue(x)\n",
    "        act = (self.w.dot(x)) + self.b\n",
    "        return act.tanh() if self.nonlin else act\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{'Tanh' if self.nonlin else 'Linear'} Neuron ({len(self.w.data)})\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8b9ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(Module):\n",
    "    def __init__(self, nin, nout, **kwargs):\n",
    "        self.neurons = [Neuron(nin, **kwargs) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x if isinstance(x, VectorValue) else VectorValue(x)\n",
    "        values = [n(x).data[0] for n in self.neurons]\n",
    "        return VectorValue(values)\n",
    "\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c54efc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorValue(data = [-0.8202342705000698, -0.19428960911256987, 0.09199830517256347])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Layer(3, 4)\n",
    "a.neurons[0].w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4941419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, nin, nouts):\n",
    "        size = [nin] + nouts\n",
    "        self.layers = [\n",
    "            Layer(\n",
    "                size[i],\n",
    "                size[i+1],\n",
    "                nonlin = i != len(nouts) -1\n",
    "                )\n",
    "            for i in range(len(nouts))\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = x if isinstance(x, VectorValue) else VectorValue(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MLP of [{', '.join(str(layer) for layer in self.layers)}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bc1bff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2, 3, -1], \n",
    "    [3, -1, 0.5], \n",
    "    [0.5, 1, 1], \n",
    "    [1, 1, -1]\n",
    "]\n",
    "\n",
    "ys = [1, -1, -1, 1]\n",
    "\n",
    "m = MLP(3, [4, 4, 1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb90c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [4.561306819182238]\n",
      "1 [4.561306819182238]\n",
      "2 [4.561306819182238]\n",
      "3 [4.561306819182238]\n",
      "4 [4.561306819182238]\n",
      "5 [4.561306819182238]\n",
      "6 [4.561306819182238]\n",
      "7 [4.561306819182238]\n",
      "8 [4.561306819182238]\n",
      "9 [4.561306819182238]\n",
      "10 [4.561306819182238]\n",
      "11 [4.561306819182238]\n",
      "12 [4.561306819182238]\n",
      "13 [4.561306819182238]\n",
      "14 [4.561306819182238]\n",
      "15 [4.561306819182238]\n",
      "16 [4.561306819182238]\n",
      "17 [4.561306819182238]\n",
      "18 [4.561306819182238]\n",
      "19 [4.561306819182238]\n",
      "20 [4.561306819182238]\n",
      "21 [4.561306819182238]\n",
      "22 [4.561306819182238]\n",
      "23 [4.561306819182238]\n",
      "24 [4.561306819182238]\n",
      "25 [4.561306819182238]\n",
      "26 [4.561306819182238]\n",
      "27 [4.561306819182238]\n",
      "28 [4.561306819182238]\n",
      "29 [4.561306819182238]\n",
      "30 [4.561306819182238]\n",
      "31 [4.561306819182238]\n",
      "32 [4.561306819182238]\n",
      "33 [4.561306819182238]\n",
      "34 [4.561306819182238]\n",
      "35 [4.561306819182238]\n",
      "36 [4.561306819182238]\n",
      "37 [4.561306819182238]\n",
      "38 [4.561306819182238]\n",
      "39 [4.561306819182238]\n",
      "40 [4.561306819182238]\n",
      "41 [4.561306819182238]\n",
      "42 [4.561306819182238]\n",
      "43 [4.561306819182238]\n",
      "44 [4.561306819182238]\n",
      "45 [4.561306819182238]\n",
      "46 [4.561306819182238]\n",
      "47 [4.561306819182238]\n",
      "48 [4.561306819182238]\n",
      "49 [4.561306819182238]\n",
      "50 [4.561306819182238]\n",
      "51 [4.561306819182238]\n",
      "52 [4.561306819182238]\n",
      "53 [4.561306819182238]\n",
      "54 [4.561306819182238]\n",
      "55 [4.561306819182238]\n",
      "56 [4.561306819182238]\n",
      "57 [4.561306819182238]\n",
      "58 [4.561306819182238]\n",
      "59 [4.561306819182238]\n",
      "60 [4.561306819182238]\n",
      "61 [4.561306819182238]\n",
      "62 [4.561306819182238]\n",
      "63 [4.561306819182238]\n",
      "64 [4.561306819182238]\n",
      "65 [4.561306819182238]\n",
      "66 [4.561306819182238]\n",
      "67 [4.561306819182238]\n",
      "68 [4.561306819182238]\n",
      "69 [4.561306819182238]\n",
      "70 [4.561306819182238]\n",
      "71 [4.561306819182238]\n",
      "72 [4.561306819182238]\n",
      "73 [4.561306819182238]\n",
      "74 [4.561306819182238]\n",
      "75 [4.561306819182238]\n",
      "76 [4.561306819182238]\n",
      "77 [4.561306819182238]\n",
      "78 [4.561306819182238]\n",
      "79 [4.561306819182238]\n",
      "80 [4.561306819182238]\n",
      "81 [4.561306819182238]\n",
      "82 [4.561306819182238]\n",
      "83 [4.561306819182238]\n",
      "84 [4.561306819182238]\n",
      "85 [4.561306819182238]\n",
      "86 [4.561306819182238]\n",
      "87 [4.561306819182238]\n",
      "88 [4.561306819182238]\n",
      "89 [4.561306819182238]\n",
      "90 [4.561306819182238]\n",
      "91 [4.561306819182238]\n",
      "92 [4.561306819182238]\n",
      "93 [4.561306819182238]\n",
      "94 [4.561306819182238]\n",
      "95 [4.561306819182238]\n",
      "96 [4.561306819182238]\n",
      "97 [4.561306819182238]\n",
      "98 [4.561306819182238]\n",
      "99 [4.561306819182238]\n",
      "[0.7901600059314516, -1.2160756731283318, 0.7912323221343661, -0.12341980919637223]\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    y_pred = [m(x) for x in xs]\n",
    "    # print(y_pred)\n",
    "    loss = sum([(yout - ygt)**2 for ygt, yout in zip(ys, y_pred)])\n",
    "    # print(f'Loss at step {k}: {loss}')\n",
    "\n",
    "    # backward\n",
    "    for p in m.parameters():\n",
    "        p.grad = [0.0 for _ in p.grad]\n",
    "    loss.backward()\n",
    "\n",
    "    for p in m.parameters():\n",
    "        for i in range(len(p.data)):\n",
    "            p.data[i] += -0.1 * p.grad[i]\n",
    "\n",
    "    print(k, loss.data)\n",
    "print([y.data[0] for y in y_pred])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrtext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
