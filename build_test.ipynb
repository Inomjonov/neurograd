{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807a7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64bceb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from turtle import backward\n",
    "import math\n",
    "\n",
    "from matplotlib.pyplot import isinteractive\n",
    "\n",
    "class VectorValue:\n",
    "    def __init__(self, data, _children = (), _op: str = \"\", label: str = \"\"):\n",
    "        if isinstance(data, (int, float)):\n",
    "            self.data = [float(data)]\n",
    "        else:\n",
    "            self.data = list(data)\n",
    "            \n",
    "        self.grad = [0.0 for _ in self.data]\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"VectorValue(data = {self.data})\"\n",
    "    \n",
    "    # Addition(s)\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, VectorValue) else VectorValue(other)\n",
    "        assert len(self.data) == len(other.data)\n",
    "\n",
    "        out_data = [a + b for a, b in zip(self.data, other.data)]\n",
    "        out = VectorValue(out_data, (self, other), \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.grad)):\n",
    "                self.grad[i] += out.grad[i]\n",
    "                other.grad[i] += out.grad[i]\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "\n",
    "    # Multiplications\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, VectorValue) else VectorValue(other)\n",
    "        assert len(other.data) == len(self.data)\n",
    "        out_data = [a * b for a, b in zip(self.data, other.data)]\n",
    "        out = VectorValue(out_data, (self, other), \"*\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.grad)):\n",
    "                self.grad[i] += other.data[i] * out.grad[i]\n",
    "                other.grad[i] += self.data[i] * out.grad[i]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    \n",
    "    # Dot product\n",
    "    def dot(self, other):\n",
    "        assert len(self.data) == len(other.data)\n",
    "        out_data = [sum(a * b for a, b in zip(self.data, other.data))]\n",
    "        out = VectorValue(out_data, (self, other), \"dot-product\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.grad)):\n",
    "                self.grad[i] += other.data[i] * out.grad[0]\n",
    "                other.grad[i] += self.data[i] * out.grad[0]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out  \n",
    "    \n",
    "    # Sum\n",
    "    def sum(self):\n",
    "        out_data = [sum(self.data)]\n",
    "        out = VectorValue(out_data, (self, ), \"sum\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += out.grad[0]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    # Activations\n",
    "\n",
    "    def relu(self):\n",
    "        out_data = [max(0.0, x) for x in self.data]\n",
    "        out = VectorValue(out_data, (self, ), \"ReLU\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += (self.data[i] > 0) * out.grad[i]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        out_data = [math.tanh(x) for x in self.data]\n",
    "        out = VectorValue(out_data, (self,), \"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += (1 - out.data[i]**2) * out.grad[i]\n",
    "        \n",
    "        out._backward = _backward\n",
    "        return out\n",
    "             \n",
    "    \n",
    "    # Negation\n",
    "    def __neg__(self):\n",
    "        return self * -1\n",
    "    \n",
    "    # Subtractions\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        return other + (-self)\n",
    "    \n",
    "    def __pow__(self, power):\n",
    "        assert isinstance(power, (int, float)), \"only supports scalar powers\"\n",
    "\n",
    "        out_data = [x ** power for x in self.data]\n",
    "        out = VectorValue(out_data, (self,), f\"**{power}\")\n",
    "\n",
    "        def _backward():\n",
    "            for i in range(len(self.data)):\n",
    "                self.grad[i] += power * (self.data[i] ** (power - 1)) * out.grad[i]\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if not v in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = [1.0 for _ in self.grad]\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "491295bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: VectorValue(data = [1.0, 2.0, 3.0])\n",
      "w: VectorValue(data = [0.5, -1.0, 2.0])\n",
      "b: VectorValue(data = [0.1])\n",
      "y: VectorValue(data = [0.9997979416121845])\n"
     ]
    }
   ],
   "source": [
    "x = VectorValue([1.0, 2.0, 3.0])\n",
    "w = VectorValue([0.5, -1.0, 2.0])\n",
    "b = VectorValue([0.1])\n",
    "\n",
    "# single neuron forward\n",
    "y = (w.dot(x) + b).tanh()\n",
    "y.backward()\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "print(\"y:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f44472f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.00545502529852554, -0.01091005059705108, 0.02182010119410216]\n",
      "w: [0.01091005059705108, 0.02182010119410216, 0.03273015179115324]\n",
      "b: [0.01091005059705108]\n",
      "y: [1.0]\n"
     ]
    }
   ],
   "source": [
    "y = (w.dot(x) + b).tanh()\n",
    "y.backward()\n",
    "\n",
    "print(\"x:\", x.grad)\n",
    "print(\"w:\", w.grad)\n",
    "print(\"b:\", b.grad)\n",
    "print(\"y:\", y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243801b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorValue(data = [1, 4, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = VectorValue([1, 2, 3])\n",
    "b = [1, 2, 3]\n",
    "a *b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cda2fd",
   "metadata": {},
   "source": [
    "### Neural-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95551850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f660707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def zer_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = [0.0 for _ in p.grad]\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4f6cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(Module):\n",
    "    def __init__(self, nin, nonlin = True):\n",
    "        self.w = VectorValue(\n",
    "            [random.uniform(-1, 1) for _ in range(nin)], \n",
    "             label='w'\n",
    "        )\n",
    "    \n",
    "        self.b = VectorValue([0.0], label='w')\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "    def __call__(self, x:VectorValue):\n",
    "        act = (self.w.dot(x)) + self.b\n",
    "        return act.tanh() if self.nonlin else act\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{'Tanh' if self.nonlin else 'Linear'} Neuron ({len(self.w.data)})\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8b9ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(Module):\n",
    "    def __init__(self, nin, nout, **kwargs):\n",
    "        self.neurons = [Neuron(nin, **kwargs) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x: VectorValue):\n",
    "        values = [n(x).data[0] for n in self.neurons]\n",
    "        return VectorValue(values)\n",
    "\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c54efc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorValue(data = [-0.2861476807732817, -0.08775453120393562, 0.06057624828001851])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Layer(3, 4)\n",
    "a.neurons[0].w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4941419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, nin, nouts):\n",
    "        size = [nin] + nouts\n",
    "        self.layers = [\n",
    "            Layer(\n",
    "                size[i],\n",
    "                size[i+1],\n",
    "                nonlin = i != len(nouts) -1\n",
    "                )\n",
    "            for i in range(len(nouts))\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, x:VectorValue):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MLP of [{', '.join(str(layer) for layer in self.layers)}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc1bff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [4.832787144060846]\n",
      "1 [4.832787144060846]\n",
      "2 [4.832787144060846]\n",
      "3 [4.832787144060846]\n",
      "4 [4.832787144060846]\n",
      "5 [4.832787144060846]\n",
      "6 [4.832787144060846]\n",
      "7 [4.832787144060846]\n",
      "8 [4.832787144060846]\n",
      "9 [4.832787144060846]\n",
      "10 [4.832787144060846]\n",
      "11 [4.832787144060846]\n",
      "12 [4.832787144060846]\n",
      "13 [4.832787144060846]\n",
      "14 [4.832787144060846]\n",
      "15 [4.832787144060846]\n",
      "16 [4.832787144060846]\n",
      "17 [4.832787144060846]\n",
      "18 [4.832787144060846]\n",
      "19 [4.832787144060846]\n"
     ]
    }
   ],
   "source": [
    "xs = [\n",
    "    VectorValue([2, 3, -1]),\n",
    "    VectorValue([3, -1, 0.5]),\n",
    "    VectorValue([0.5, 1, 1]),\n",
    "    VectorValue([1, 1, -1])\n",
    "]\n",
    "\n",
    "ys = [VectorValue([1]), VectorValue([-1]), VectorValue([-1]), VectorValue([1])]\n",
    "\n",
    "m = MLP(3, [4, 4, 1])\n",
    "\n",
    "for k in range(20):\n",
    "\n",
    "    y_pred = [m(x) for x in xs]\n",
    "\n",
    "    losses = []\n",
    "    for ygt, yout in zip(ys, y_pred):\n",
    "        diff = yout -ygt\n",
    "        losses.append(diff * diff)\n",
    "\n",
    "    loss = losses[0]\n",
    "    for l in losses[1:]:\n",
    "        loss = loss + l\n",
    "\n",
    "    for p in m.parameters():\n",
    "        p.grad = [0.0 for _ in p.grad]\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in m.parameters():\n",
    "        for i in range(len(p.data)):\n",
    "            p.data[i] += -0.01 * p.grad[i]\n",
    "\n",
    "    print(k, loss.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrtext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
